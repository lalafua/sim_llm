import requests
import rclpy
import json
import os
import threading
from rclpy.node import Node
from my_interfaces.srv import Command
from rclpy.executors import MultiThreadedExecutor

DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
PROMPT = """
    You are the most accurate command parser! Your task is to transfer information between human and robot.
    
    CLASS_NAME = (
        'mask',
        'phone',
        'bottle',
        'gloves',
        'metal',
        'palstic bag',
        'sunglasses',
        'boll',
        'door',
        'other',
    )

    # Instructions
    - First, Abstracting actionable words from conversations.
    - Second, Compare the object to the object in CLASS_NAME and choose the word with the closest meaning to replace it.
    - Finally, Generate a json string.

    # Example
    conversation: give me a garbage bag.
    answer:{
        "commands":[
            {
                "command": "find",
                "parms":{
                    "object":"palstic bag"
                }
            }
            {
                "command": "give",
                "parms":{
                    "object":"palstic bag"
                
            }
        ]
    }

    conversation: find my Coke.
    answer:{
        "commands":[
            {
                "command": "find",
                "parms":{
                    "object":"bottle"
                }
            }
        ]
    }

    conversation: pick up my phone and close the door.
    answer:{
        "commands":[
            {
                "command": "pick_up",
                "parms":{
                    "object": "phone"
                }
            },
            {
                "command": "close",
                "parms":{
                    "object": "door"
                }
            }
        ]
    }
"""

class NLPNode(Node):
    def __init__(self, name):
        # Initialize the node
        super().__init__(name)
        self.get_logger().info("Node {} has been created.".format(name))
        
        self.command_client_ = self.create_client(Command, "/llm_nlp/cmd")
        self.request = Command.Request()

        # Start a thread to wait for user input
        self.input_thread = threading.Thread(target=self.wait_for_input)
        self.input_thread.daemon = True
        self.input_thread.start()
    
    def dps_genai(self, msg):
        """
        This function uses the large language model to generate a response from the prompt.
        
        Args:
            prompt(str): The prompt to generate
        
        Return:
            response.text(str): Json string generated by Gemini
        """

        api_url = "https://api.deepseek.com/chat/completions"
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer {}".format(DEEPSEEK_API_KEY)
        }
        payload = {
            "model": "deepseek-chat",
            "message": [
                {
                    "role": "system",
                    "content": PROMPT
                },
                {
                    "role": "user",
                    "content": msg
                }
            ],
            "stream": False
        }

        try:
            response = requests.post(
                url=api_url,
                headers=headers,
                json=payload,
                timeout=20
            )

            response.raise_for_status()

            response_data = response.json()

            print(json.dumps(response_data, indent=4))

            if 'choices' in response_data and len(response_data['choices']) > 0:
                response_content = response_data['choices'][0]['message']['content']
                response_content = response_content.replace("```json", "").replace("```", "").strip()
                print(response_content)

        except requests.exceptions.RequestException as e:
            print("Error: {}".format(e))
            if hasattr(e, 'response') and e.response is not None:
                print(f"Status Code: {e.response.status_code}")
                try:
                    print(f"Error Body: {e.response.json()}")
                except json.JSONDecodeError:
                    print(f"Error Body: {e.response.text}")

        except Exception as e:
            print("Error: {}".format(e))

        return response_content
    
    def wait_for_input(self):
        """
        This function waits for user input and sends the input as a service request.
        """

        # Wait for the command service to be available  
        while not self.command_client_.wait_for_service(timeout_sec=5.0):
            self.get_logger().info("Wait for service '/nlp/nlp_cmd' ")

        user_input = input("Enter a command: ")
        
        request_json = self.dps_genai(user_input)

        self.request.command = request_json
        self.get_logger().info("Request: \n{}".format(self.request.command))    

        future = self.command_client_.call_async(self.request)
        future.add_done_callback(self.handle_response)

    def handle_response(self, future):
        """
        This function handles the response from the command service.
        """

        try:
            response = future.result()
            self.get_logger().info("Response: {}".format(response.is_success))
            if response.is_success:
                self.wait_for_input()
            else:
                self.get_logger().fatal("Oops! something went wrong")
                self.wait_for_input()
        except Exception as e:
            self.get_logger().error("Service call failed {}".format(e))
        
         
def main(args=None):
    rclpy.init(args=args)
    nlp_node = NLPNode("llm_nlp")
    executor = MultiThreadedExecutor()
    executor.add_node(nlp_node)

    try:
        executor.spin()
    except KeyboardInterrupt:
        pass        
    finally:
        nlp_node.destroy_node()
        rclpy.shutdown()

if __name__ == "__main__":
    main()
